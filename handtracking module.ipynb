{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                             Hand Tracking project:           \n",
    "  This code uses the OpenCV and MediaPipe libraries to capture video from the device's camera and track the hand(s) in the frames. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Mediapipe: \n",
    "                    MediaPipe is an open-source framework developed by Google for building cross-platform, multidevice, multimodal applied machine learning pipelines. It is designed to help developers and researchers create applied ML solutions that work on various devices and platforms, such as smartphones, laptops, and embedded devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "\n",
    "# for video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "mphands = mp.solutions.hands\n",
    "hands = mphands.Hands()\n",
    "mpDraw = mp.solutions.drawing_utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which takes an integer argument specifying the camera to use (in this case, 0 for the default camera)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    success, img=cap.read()\n",
    "    # img = cv2.flip(img, 1)\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(imgRGB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  The while loop captures frames from the camera and processes them to detect hands. If hands are present in the frame, the code loops through the hand landmarks, drawing circles at the x,y coordinate of each landmark and connecting the landmarks using lines to form a skeleton of the hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if hands are present  in the picture\n",
    "    if results.multi_hand_landmarks:\n",
    "        for handlms in results.multi_hand_landmarks:\n",
    "            for id, lm in enumerate(handlms.landmark):\n",
    "                h, w, c = img.shape\n",
    "                cx, cy = int(lm.x*w), int(lm.y*h)\n",
    "                print(id, cx, cy)\n",
    "                if id == 0:\n",
    "                    cv2.circle(img,(cx, cy), 25, (255, 0, 255), cv2.FILLED)\n",
    "\n",
    "            mpDraw.draw_landmarks(img, handlms, mphands.HAND_CONNECTIONS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If hands are present in the frame, the code loops through the hand landmarks, drawing circles at the x,y coordinate of each landmark and connecting the landmarks using lines to form a skeleton of the hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ctime = time.time()\n",
    "    fps = 1/(ctime-ptime)\n",
    "    ptime = ctime\n",
    "    # cv2.putText(img, str(handlms),(10, 70),cv2.FONT_HERSHEY_PLAIN,3,(255,0,255),3)\n",
    "    cv2.putText(img, str(int(fps)), (10, 70),cv2.FONT_HERSHEY_PLAIN,3,(255,0,255),3)\n",
    "    cv2.imshow(\"image\", img)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it show final result and fps on screen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9549edd590dad2e47b68bb89a9110a6a20f987ff2529a71a9123232dd873c47e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
