# HandTracking-Mediapipe
MediaPipe is an open-source, cross-platform library for building multimodal (e.g. video, audio, sensor) applied ML pipelines. The Hand Tracking MediaPipe project is a demonstration of how MediaPipe can be used to track the movement of hands in real-time video. It uses a machine learning model to infer the location and orientation of the hands in each frame of the video, and then renders a 3D representation of the hand on top of the video. The pipeline is optimized for performance on mobile devices and can run in real-time on smartphones or tablets. It is a good example for developers looking to build similar hand tracking applications, or to learn how to use MediaPipe for other multimodal ML projects.
# RESULT
![handresult](https://user-images.githubusercontent.com/96516609/213776608-0cd914b0-ef77-41c3-b890-60a7f2d59668.jpg)
![handresult2](https://user-images.githubusercontent.com/96516609/213775813-259f3be8-54f2-4f26-ab0b-e4fc6df7a8aa.jpg)



